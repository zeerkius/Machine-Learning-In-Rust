This project is a high-performance image pre-processing pipeline built in Rust, designed to streamline data preparation for machine learning workflows. It efficiently processes raw image datasets through a series of customizable pre-processing stagesâ€”such as resizing, normalization, and format conversionâ€”and outputs clean, structured data in CSV format, ready for model training.

âœ¨ Key Features

âš¡ Blazing-fast performance powered by Rustâ€™s zero-cost abstractions

ğŸ§  ML-ready output â€” automatically generates a .csv file compatible with most ML frameworks

ğŸ§© Modular pre-processing stages (e.g., resizing, normalization, grayscale conversion, and more)

ğŸ§° Customizable pipeline â€” easily extend or modify steps for your specific dataset

ğŸ“¦ Lightweight and reliable with minimal dependencies

ğŸš€ Ideal For

Preparing large image datasets for machine learning or deep learning tasks

Converting raw image folders into structured numerical representations

Researchers and developers who value speed, safety, and reproducibility

ğŸ§ª Example Workflow
# Run the pre-processor on a dataset directory
cargo run -- --input ./dataset --output ./processed/data.csv


This command:

Loads images from ./dataset

Applies your chosen pre-processing pipeline

Exports features and labels to data.csv

ğŸ› ï¸ Tech Stack

Language: Rust ğŸ¦€

Data Format: CSV for ML compatibility

Focus: Performance, safety, and modularity
